[
    {
        "text": "Confidence Measure for Blo ck-Based Motion Vector Field \nKaren Simonyan, Sergey Grishin, and Dmitriy Vatolin \nGraphics and Media Laboratory, Department of  Computational Mathematics and Cybernetics \nMoscow State University, Moscow, Russia  \n{simonyan, sgrishin, dmitriy}@graphics.cs.msu.ru \n \nAbstract \nIn this paper we propose a conf idence measure for block-based \nmotion vector field. The measure is calculated as an average of \ntwo a posteriori  estimates which reflect various aspects of MVF \naccuracy: motion-compensated interframe difference distribution and motion vectors distribution. E xperimental results show that \nthe proposed measure outperforms its contemporary counterpart \nwhile demanding less informati on about the motion estimation \nprocess. Keywords: confidence measure, motion estimation, motion vector \nfield. 1. INTRODUCTION \nMotion information is used in most contemporary video \nprocessing algorithms, as it allows getting benefit from video redundancy, thereby enhancing the algorithm performance. Since ground-truth Motion Vector Field (MVF) is usually not available, a Motion Estimation (ME) algorithm is applied to calculate the \nmotion between video frames. The correspondence of the calculated motion to a ground-truth motion is one of the key issues, as the utilization of wrong motion information ( e.g. caused \nby aperture problem or occlusion [7]) can lead to artifacts in the \nareas of the processed video, wh ere this information is used. Therefore, certain objective crite rion is needed to express the \ncorrespondence. The confidence measure is such a criterion. It can be treated as a \nprobability that an estimated Moti on Vector (MV) is equal to a \nground-truth MV.",
        "page": 1
    },
    {
        "text": "Therefore, certain objective crite rion is needed to express the \ncorrespondence. The confidence measure is such a criterion. It can be treated as a \nprobability that an estimated Moti on Vector (MV) is equal to a \nground-truth MV. The confidence meas ure is a universal means to \ncontrol MVF correctness, as it can be applied in two scenarios: \n• the measure can be incorporated directly into the conventional ME algorithm to detect wrongly estimated MVs. A special postprocessing is  then applied to these MVs to improve their accuracy; \n• the measure can be a part of video postprocessing algorithm ( e.g. frame rate up-conversion or \ndeinterlacing) executed on the decoder side, where the information about the ME process is inaccessible. In this case a separate branch of the algorithm can be provided to handle the processing of areas, for which no reliable motion information is available. In this paper we propose a conf idence measure for block-based \nMVF, which takes different spa tial and temporal cues into \naccount. The results of the comp arison with the method proposed \nby Patras et al. [1] justify the superiority of the proposed method. The rest of the paper is organi zed as follows. In Section 2 a \nreview of the related work is given. In Section 3 the proposed \nalgorithm is described. Experime ntal results are presented in \nSection 4. Section 5 concludes the paper. 2. RELATED WORK \nThere are two major approaches [1] to a confidence measure \ncalculation.",
        "page": 1
    },
    {
        "text": "In Section 2 a \nreview of the related work is given. In Section 3 the proposed \nalgorithm is described. Experime ntal results are presented in \nSection 4. Section 5 concludes the paper. 2. RELATED WORK \nThere are two major approaches [1] to a confidence measure \ncalculation. The first is to estimate a priori  confidence to a MV \nbefore its explicit calculation. Generally, such methods take \ncertain spatial cues into account, e.g. spatial luminance \nderivatives [3], [4]. The basic idea is to determine the areas where \nthe aperture problem can arise. This information can further be used to decide whether ME can be confidently applied to certain area, or not [2]. The major drawback of this technique is a small \napplication field, as the approach is almost useless when a \nconfidence to an estimated MVF is to be obtained. The second approach assumes the calculation of a posteriori  \nconfidence to already estimated MVF. In this case not only the \nspatial cues can be used, but proper MVF modeling and analysis \nas well. The methods following this approach can be divided into two groups according to the MVF structure. The first group is \nformed by the methods intended for optical flow confidence \nestimation [5], [6]. The second group consists of the algorithms \nestimating confidence to a block MVF, e.g. the MVF calculated \nby block matching ME. These algorithms are of particular interest, since block matching ME is widely used in conventional \nvideo processing systems. In [7] To et al.",
        "page": 1
    },
    {
        "text": "The second group consists of the algorithms \nestimating confidence to a block MVF, e.g. the MVF calculated \nby block matching ME. These algorithms are of particular interest, since block matching ME is widely used in conventional \nvideo processing systems. In [7] To et al. proposed a confidence \nmeasure based on frame phase in formation, thus limiting the \napplication field of the method within cases where phase \ncorrelation ME is used. Lundmark et al. [8] used the weighted \nsum of Motion-Compensated Inte rframe Difference (MCID) to \nobtain the confidence value. This algorithm is applicable in the \ncase of occlusion, but in the case of aperture problem it fails. Recently Patras et al. [1] introduced a confidence measure in the \nprobabilistic framework. They proved that the block-based ME \nminimizing the Sum of Absolute Di fferences (SAD) is equivalent \nto a maximum likelihood estimator of MVs, assuming that the MCID follows the Laplacian distribution. Considering candidate motion vectors for each block to be known, a posteriori  \nprobability of calculated MV being equal to a ground-truth MV is estimated. However, the dependence on the candidate set is a disadvantage, since: \n• all the candidates must be known. Therefore, the measure can be calculated only while performing ME. This fact impedes the application of the measure in video processing on the decoder side, as candidate motion vectors are unavailable in a video stream; \n• contemporary block matching methods [9] use various \nMVF consistency cues to redu ce the candidate set, thus \ngaining efficiency. However, this can lead to erroneous \nconfidence estimates.",
        "page": 1
    },
    {
        "text": "However, this can lead to erroneous \nconfidence estimates. For instance, ME algorithm can \nwrongly construct a candidate set of one MV, \nnevertheless Patras et al. measure will assign a unity \n(i.e. highest) confidence to the vector because there are \nno other vectors in the set. Thereby, the measure can be applied only to pattern search ME methods, e.g. full-\nsearch. 3. PROPOSED CONFIDENCE MEASURE \nThe proposed confidence measure is derived in the following \nway. Two a posteriori  estimates of MV confidence are obtained. The first estimate, , is based on MCID analysis. The \nsecond estimate, , takes MVF distribution into account. These estimates are combined, resulting in a confidence measure. Various schemes of estimates combination exist. Kittler et al. MCIDP\nMVFP\n[10] \nargued that in practice simple averaging often produces better results than more sound techniques do. From our experiments, we \ncame to the same conclusion. So, the measure is calculated as: \n2MVF MCID P PP+= . (1)  \nThe derivation of the estimates  and  is given in \nSections MCIDPMVFP\n3.1 and 3.2 respectively. 3.1 MCID analysis \nAs in [1] , we consider the case where SAD is used as an error \nfunction for MV and assume that the MCID follows the Laplacian distribution with a zero mean: \n()()()\n⎟⎟\n⎠⎞\n⎜⎜\n⎝⎛\n− =\nB Bx Ix I Pλ λexp21, (2)  \nwhere  is a MCID value of pixel ()x I x from block , BBλ is a \nparameter, specific to the block.",
        "page": 1
    },
    {
        "text": "The variance  of block \nMCID is linked with MCID\nBσ\nBλ by the following expression: \nBMCID\nB λ σ 2= . (3)  \nGiven the sample (){}B x x I∈  a maximum likelihood estimate of \nBλ can be derived as follows: \n()()\n()\n()\n() ().SAD SAD\n21ln max argSADexp21max argexp21max argmax arg\nBB BBBx Ix I P\nB BBB\nBBB xB\nBB xB\nBBBB\n=⎟⎟\n⎠⎞\n⎜⎜\n⎝⎛− ⋅ ==\n⎟⎟⎟\n⎠⎞\n⎜⎜⎜\n⎝⎛\n⎟⎟\n⎠⎞\n⎜⎜\n⎝⎛− ⋅⎟⎟\n⎠⎞\n⎜⎜\n⎝⎛==\n⎟⎟⎟\n⎠⎞\n⎜⎜⎜\n⎝⎛\n⎟⎟⎟\n⎠⎞\n⎜⎜⎜\n⎝⎛∑\n− ⋅⎟⎟\n⎠⎞\n⎜⎜\n⎝⎛== =\n∈∈∏\nλ λλ λλ λλ\nλλλλ\n (4)  \nThus, only the SAD value of the bl ock MV is needed to obtain the \nestimate of Bλ. In [1] it was suggested that   depends on block luminance \nvariance : the larger , the larger . The \nargumentation is as follows. If the value of  is low (uniform \nblock), and a good reference block was found by ME, the variance of motion-compensated difference between the current \nand the reference blocks  will also be low. On the \ncontrary, it is quite natural to suppose that for large  values \n(e.g. block containing fine texture) the value of  will be \nlarge as no perfect match is usually possible in such cases. We \napproximate this dependence with a linear function: \nMCID\nBσ\nI\nBσI\nBσMCID\nBσ\nI\nBσMCID\nBσ\nβ α+0 0I\nBσ\nMCID\nBσ\nI\nBMCID\nB σ σ ⋅ = , (5)  \nwhere 0α and 0β are constants specific for each video frame.",
        "page": 2
    },
    {
        "text": "We \napproximate this dependence with a linear function: \nMCID\nBσ\nI\nBσI\nBσMCID\nBσ\nI\nBσMCID\nBσ\nβ α+0 0I\nBσ\nMCID\nBσ\nI\nBMCID\nB σ σ ⋅ = , (5)  \nwhere 0α and 0β are constants specific for each video frame. The dependence between I\nBσ d M\nBσ otted for one frame \nof Fly test video (test videos are described in Section CID,  an  pl\n4) is \npresented in Figure 1 together with the approximant function. 2\n0 5 10 15 2000.51\nσB I  \n1.5linear approximant\ndependenceσB MCID\nFigure 1: The dependence of  MCID\nBσ  on I\nBσ for Fly frame \nand the correspondent linear approximant. Substituting (3) and (4) into (5), we derive: \n() I\nBBBσ β α⋅ + =SAD, (6)  \nwhere () ()T T\n0 0,\n21, β α β α≡ . Assuming that ()B SAD  and  are known for each block  \nof the frame, I\nBσ B\nα and β are calculated using linear least squares \nmethod, which leads to the following estimates: \n()() ()\n()\n() ()\n(),SAD SAD,SAD SAD\n22222\n⎟⎟\n⎠⎞\n⎜⎜\n⎝⎛−⋅ −\n=⎟⎟\n⎠⎞\n⎜⎜\n⎝⎛−⋅ − ⋅\n=\n∑ ∑∑ ∑ ∑∑ ∑∑ ∑ ∑ ∑\nBI\nB\nBI\nBB BI\nB\nBI\nBBI\nB\nBI\nBBI\nB\nBI\nB\nB BI\nB\nnBB\nBBnnBB\nBB\nσ σσ σ\nβσ σσ σ σ\nα\n (7)  \nwhere  is the number of blocks in a frame. n",
        "page": 2
    },
    {
        "text": "n To obtain a  value for a block , an estimate of its SAD \nvalue is calculated: MCIDP B\n()()I\nB B Bσ β α⋅ + = SAD' , (8)  \nand finally,   \n()\n()⎟⎟\n⎠⎞\n⎜⎜\n⎝⎛\n⎟⎟\n⎠⎞\n⎜⎜\n⎝⎛= 1 , 0 ,SADSAD'max minBBPMCID . (9)  \n3.2 MVF analysis \nThe estimate  reflects the confidence to a MV based on the \nMVF distribution analysis. Here we utilize the following \nheuristics. If the block MV is clos e in some sense to the MVs of \nadjacent blocks, it is likely that th e blocks correspond to a part of \nobject, exhibiting uniform motion, so the confidence is assigned to the block depending on the size of the object part. On the contrary, if the block MV differs from adjacent blocks’ MVs, it can be a wrong vector. This cue leads to the following algorithm:  MVFP\n• cluster the MVF in some manner; \n• let BC be the cluster which the block B belongs to; \nthen MVFP  is calculated as: \n⎟⎟\n⎠⎞\n⎜⎜\n⎝⎛\n= 1 , minthreshCPB\nMVF , (10)\nwhere  is a threshold, which value is chosen \nempirically. In our experiments the value was set to \n0.5% of the frame area. thresh\nAs it can be seen, the performance of this part of confidence estimation algorithm essentially depends on the clustering algorithm chosen. We employed a modification of an agglomerative hierarchical clustering algorithm [11] that \nmaintains clusters’ spatial cons istency.",
        "page": 2
    },
    {
        "text": "thresh\nAs it can be seen, the performance of this part of confidence estimation algorithm essentially depends on the clustering algorithm chosen. We employed a modification of an agglomerative hierarchical clustering algorithm [11] that \nmaintains clusters’ spatial cons istency. Such choice of the \nclustering algorithm (that will be discussed further) was driven by several reasons: \n• the number of clusters in a frame is a priori  unknown; \n• the clusters on the output of the algorithm must be spatially consistent frame regions. The distance between blocks is introduced as the  distance \nbetween corresponding MVs: \n2L\n() ( )( )22 1 2 1, B MV B MV B B d− = , (11)\nwhere ()2 , 1B MV\nC is the MV of block . The distance \nbetween clusters  and  is calculated as the mean distance \nbetween cluster elements (the so-called average linkage clustering): 2 , 1B\n1 2C\n() ()∑∑\n∈∈⋅=\n12,1,\n2 12 1\nCBC Bj i\nijB B dC CC C d . (12)\nUnlike conventional agglomerative hierarchical clustering, the \nproposed clustering algorithm at each step merges spatially \nadjacent  clusters, distance between which is minimal. The \nmerging process is stopped when  the minimal distance between \nadjacent clusters exceeds a certain threshold. Empirically the threshold was set to the mean length of the frame MVs; thereby the clustering adapts to the mo tion activity in the frame. An \nexample of MVF clustering for one frame of Fly test video is \ndemonstrated in Figure 2; different clusters are painted with different colors.",
        "page": 3
    },
    {
        "text": "Empirically the threshold was set to the mean length of the frame MVs; thereby the clustering adapts to the mo tion activity in the frame. An \nexample of MVF clustering for one frame of Fly test video is \ndemonstrated in Figure 2; different clusters are painted with different colors. Figure 2: Clustered MVF of Fly frame. 4. EXPERIMENTAL RESULTS \nTo evaluate the performance of th e proposed measure, we used a \ntest set of two synthetica lly rendered video sequences, Fly and \nTower , for which ground-truth MVF is available. These videos \nare in 576 720×  resolution and consist of 151 frames. Full-\nsearch ME algorithm ( 16 16×  blocks were used, MVs were \nestimated with a quarter-pixel accuracy) was applied to these videos, resulting in MVFs that were further used to compare confidence measures. After that, two confidence estimation algorithms, the proposed one and the method by Patras et al. [1], \nwere used to obtain the confidence measure values for these MVFs. Then, Spearman and Kendall rank correlation coefficients \n[12] were calculated between each of these measures and the \nground-truth error score . This score is defined as: \nΔGT\n()( )2B MV B MV GTGT FS− =Δ , (13)\nwhere ()B MVFS  is a MV of block , obtained by the full-\nsearch ME, B\n()B MVGT  is a ground-truth MV of this block. The so-called Spearman’s rho ρ and Kendall’s tau τ are quite \npopular measures to evaluate  the correspondence between \ndifferent scores for the same group of objects.",
        "page": 3
    },
    {
        "text": "The so-called Spearman’s rho ρ and Kendall’s tau τ are quite \npopular measures to evaluate  the correspondence between \ndifferent scores for the same group of objects. Thus, it can be \ndetermined how much the compared confidence measures correspond to the ground-truth error. Table I    \nComparison of median \nρ and τ for the compared algorithms \nVideo sequence \nFly Tower Confidence \nmeasure \nalgorithm medianρ medianτ medianρ medianτ \nProposed 0.3219 0.2867 0.5628 0.4631 \nPatras  \net al. 0.2724 0.2388 0.4596 0.3491 The results of the comparison of ρ and τ median values \ncalculated for test videos are given in Table I . Plots of \nSpearman’s rho for  Fly  and  Tower   videos are presented in \nFigure 3 and Figure 4 respectively. The plots of Kendall’s tau are \nnot given as the results of τ comparison very closely follow \nthose of ρ comparison. As it can be seen, the proposed \nconfidence measure outperforms Patras et al. measure, providing \nacceptable rank correlation with the ground-truth score. 6. REFERENCES \n[1] I. Patras, E. A. Hendriks, a nd R. L. Lagendijk. Probabilistic \nConfidence Measures for Block Matching Motion Estimation. IEEE \nTrans. on CSVT , Aug. 2007, vol.17, pp. 988–995. [2] P. Sand and L. McMillan. Efficient selection of image patches with \nhigh motion confidence. In Proc. IEEE ICIP , Rochester, NY, 2002, \npp. 293–296. [3] J. Barron, D. Fleet, and S. Beauchemin. Performance of optical flow \ntechniques. In Proc. IJCV , 1994, vol. 12, no. 1, pp. 43–77. 20 40 60 80 100 120 140-0.100.10.20.30.40.5\nFrame numberSpearman's  ρ\n Patras  et al.",
        "page": 3
    },
    {
        "text": "In Proc. IEEE ICIP , Rochester, NY, 2002, \npp. 293–296. [3] J. Barron, D. Fleet, and S. Beauchemin. Performance of optical flow \ntechniques. In Proc. IJCV , 1994, vol. 12, no. 1, pp. 43–77. 20 40 60 80 100 120 140-0.100.10.20.30.40.5\nFrame numberSpearman's  ρ\n Patras  et al. algorithm\nProposed algorithm\n \nFigure 3: Comparison of Spearman’s rho on Fly video. [4] T. Yoshida, H. Katoh, and Y. Sakai. Block matching motion \nestimation using block integrati on based on reliability metric. In \nProc. IEEE ICIP , 1997, vol. 2, pp. 152–155. [5] E. P. Simoncelli, E. H. Adelson, and D. J. H eeger. Probability \ndistributions of optical flow. In Proc. IEEE ICCVPR, Maui, HI, Jun. 1991, pp. 310–315. [6] A. Dev, B. J. A. Krose, and F. C. A. Groen. Confidence measures for \nimage motion estimation. In Proc. RWC Symposium , 1997, pp. 199–\n206. [7] L. To, M. Pickering, M. Frater, and J. Arnold. A motion confidence \nmeasure from phase information. In Proc. IEEE ICIP , Oct. 2004, vol. IV, pp. 2583–2586. [8] A. Lundmark, H. Li, and R. Forchheimer. Motion vector certainty \nreduces bit rate in backward motion estimation video coding. In \nProc. SPIE VCIP , Jun. 2000, pp. 95–105. [9] Ahmad, I., Zheng, W.G., Luo, J.C., Liou, M. A Fast Adaptive \nMotion Estimation Algorithm. IEEE Trans. on Image Processing , \n2006, vol. 16, issue 3, pp. 420–438. 20 40 60 80 100 120 1400.30.40.50.60.70.8\nFrame numberSpearman's  ρ\n Patras  et al. algorithm\nProposed algorithm\n \nFigure 4: Comparison of Spearman’s rho on Tower  video.",
        "page": 4
    },
    {
        "text": "IEEE Trans. on Image Processing , \n2006, vol. 16, issue 3, pp. 420–438. 20 40 60 80 100 120 1400.30.40.50.60.70.8\nFrame numberSpearman's  ρ\n Patras  et al. algorithm\nProposed algorithm\n \nFigure 4: Comparison of Spearman’s rho on Tower  video. [10] J. Kittler, M. Hatef, R. P. W. Du in, and J. Matas. On combining \nclassifiers. IEEE Trans. on PAMI, vol. 20, no. 3, pp. 226–239,  \nMar. 2000. [11] R. Duda, P.E. Hart, D.G. Stork. Pattern Classification. 2nd ed., \nWiley-Interscience, 2001. [12] D. Sheskin. Handbook of parametric and nonparametric statistical \nprocedures . 2nd ed., Chapman & Hall/CRC, 2000. Acknowledgement \nThe authors would like to thank the Ph.D. student Anatoly \nZapadinsky for synthetic vi deo sequences and corresponding \nground-truth MVF. About the authors \nKaren Simonyan is a student at Graphics and Media Laboratory, \nDepartment of Computational Mathematics and Cybernetics, \nMoscow State University. His research interests include motion estimation, super-resolution, fra me-rate conversion and adjacent \nfield. His contact email is simonyan@graphics.cs.msu.ru\n  5. CONCLUSION \nIn this paper we presented a new confidence measure estimation algorithm. It was argued that the algorithm produces plausible confidence estimates in terms of  rank correlation with the ground-\ntruth error score. At the same time, only the current video frame \nand its motion vectors with correspondent errors are needed to calculate the measure; no supplementary information is needed. Sergey Grishin is a Ph.D. student at Graphics and Media Laboratory, Department of Computational Mathematics and Cybernetics, Moscow State University. His research interests include deblocking, motion estim ation, frame-rate conversion, \nstereo vision and video segmenta tion.",
        "page": 4
    },
    {
        "text": "Sergey Grishin is a Ph.D. student at Graphics and Media Laboratory, Department of Computational Mathematics and Cybernetics, Moscow State University. His research interests include deblocking, motion estim ation, frame-rate conversion, \nstereo vision and video segmenta tion. His contact email is \nsgrishin@graphics.cs.msu.ru\n The performance of the algorithm can be further improved by employing more advanced clustering and robust approximation of the dependence between the variance of block intensity and the variance of its motion-compen sated interframe difference. Moreover, motion trajectory smoot hness can be an additional cue \nto be utilized in the confidence estimate derivation. Dmitriy Vatolin is an expert in image, video and data compression with more than 14 years experience; Ph.D. in image compression, IEEE Member. He is a senior researcher and the head of the Video Group at Graphics and Media Laboratory, Department of Computational Mathematics and Cybernetics, \nMoscow State University. His contact email is \ndmitriy@graphics.cs.msu.ru",
        "page": 4
    }
]